{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ce94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53f2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # insert to hold data\n",
    "# job_title = []\n",
    "# company_name = []\n",
    "# short_description = []\n",
    "# job_location = []\n",
    "\n",
    "# job_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8fcc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indeed_jobs_div(job_title, location):\n",
    "    getVars = {'q' : job_title, 'l' : location, 'fromage' : 'last', 'sort' : 'date'}\n",
    "    url = ('https://au.indeed.com/jobs?' + urllib.parse.urlencode(getVars))\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    job_soup = soup(id=\"resultContent\")\n",
    "    return job_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28ecdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(job_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e94538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title_indeed(job_elem):\n",
    "    title_elem = job_elem.find('h2', class_='jobTitle')\n",
    "    title = title_elem.text.strip()\n",
    "    return title\n",
    "\n",
    "def extract_company_indeed(job_elem):\n",
    "    company_elem = job_elem.find('span', class_='companyName')\n",
    "    company = company_elem.text.strip()\n",
    "    return company\n",
    "\n",
    "def extract_location_indeed(job_elem):\n",
    "    loc_elem = job_elem.find('div', class_='companyLocation')\n",
    "    loc= loc_elem.text.strip()\n",
    "    return loc\n",
    "\n",
    "def extract_desc_indeed(job_elem):\n",
    "    description_elem = job_elem.find('div', class_='job-snippet')\n",
    "    description = description_elem.text.strip()\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0554f2d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m job_elems \u001b[38;5;241m=\u001b[39m \u001b[43mjob_soup\u001b[49m\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmosaic-zone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'job_soup' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "job_elems = job_soup.find_all('div', class_='mosaic-zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "extracted_info = []\n",
    "\n",
    "\n",
    "if 'titles' in desired_characs:\n",
    "    titles = []\n",
    "    cols.append('titles')\n",
    "    for job_elem in job_elems:\n",
    "        titles.append(extract_job_title_indeed(job_elem))\n",
    "    extracted_info.append(titles)                    \n",
    "\n",
    "if 'companies' in desired_characs:\n",
    "    companies = []\n",
    "    cols.append('companies')\n",
    "    for job_elem in job_elems:\n",
    "        companies.append(extract_company_indeed(job_elem))\n",
    "    extracted_info.append(companies)\n",
    "\n",
    "if 'links' in desired_characs:\n",
    "    links = []\n",
    "    cols.append('links')\n",
    "    for job_elem in job_elems:\n",
    "        links.append(extract_link_indeed(job_elem))\n",
    "    extracted_info.append(links)\n",
    "\n",
    "if 'date_listed' in desired_characs:\n",
    "    dates = []\n",
    "    cols.append('date_listed')\n",
    "    for job_elem in job_elems:\n",
    "        dates.append(extract_date_indeed(job_elem))\n",
    "    extracted_info.append(dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
